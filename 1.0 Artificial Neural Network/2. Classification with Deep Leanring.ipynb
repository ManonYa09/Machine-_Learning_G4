{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "169135b0-662c-47e3-a813-919dd6158bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf, pandas as pd, seaborn as sns, numpy as np, matplotlib.pyplot as plt\n",
    "import warnings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a6f4ee8-cf85-4b09-bc98-fad238245e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Normalization, Dense, InputLayer\n",
    "from tensorflow.keras.losses import MeanSquaredError, Huber, MeanAbsoluteError\n",
    "from tensorflow.keras.metrics import RootMeanSquaredError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "718d4d2d-516a-48ee-af6b-7fa2b51fe821",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/ManonYa09/Machine-_Learning_G4/refs/heads/main/Dataset/4.%20WA_Fn-UseC_-Telco-Customer-Churn.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a759e13c-385d-4812-a494-d751a20023e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7h/0019w3h141s2b0z27906x13c0000gn/T/ipykernel_62038/2767291496.py:1: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df['Churn'] = df['Churn'].replace({'Yes':1, 'No':0})\n"
     ]
    }
   ],
   "source": [
    "df['Churn'] = df['Churn'].replace({'Yes':1, 'No':0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "edb368e2-f10c-47f8-abec-2d92bf1b2aec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customerID</th>\n",
       "      <th>gender</th>\n",
       "      <th>SeniorCitizen</th>\n",
       "      <th>Partner</th>\n",
       "      <th>Dependents</th>\n",
       "      <th>tenure</th>\n",
       "      <th>PhoneService</th>\n",
       "      <th>MultipleLines</th>\n",
       "      <th>InternetService</th>\n",
       "      <th>OnlineSecurity</th>\n",
       "      <th>...</th>\n",
       "      <th>DeviceProtection</th>\n",
       "      <th>TechSupport</th>\n",
       "      <th>StreamingTV</th>\n",
       "      <th>StreamingMovies</th>\n",
       "      <th>Contract</th>\n",
       "      <th>PaperlessBilling</th>\n",
       "      <th>PaymentMethod</th>\n",
       "      <th>MonthlyCharges</th>\n",
       "      <th>TotalCharges</th>\n",
       "      <th>Churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7590-VHVEG</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>1</td>\n",
       "      <td>No</td>\n",
       "      <td>No phone service</td>\n",
       "      <td>DSL</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Electronic check</td>\n",
       "      <td>29.85</td>\n",
       "      <td>29.85</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5575-GNVDE</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>34</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>DSL</td>\n",
       "      <td>Yes</td>\n",
       "      <td>...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>One year</td>\n",
       "      <td>No</td>\n",
       "      <td>Mailed check</td>\n",
       "      <td>56.95</td>\n",
       "      <td>1889.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   customerID  gender  SeniorCitizen Partner Dependents  tenure PhoneService  \\\n",
       "0  7590-VHVEG  Female              0     Yes         No       1           No   \n",
       "1  5575-GNVDE    Male              0      No         No      34          Yes   \n",
       "\n",
       "      MultipleLines InternetService OnlineSecurity  ... DeviceProtection  \\\n",
       "0  No phone service             DSL             No  ...               No   \n",
       "1                No             DSL            Yes  ...              Yes   \n",
       "\n",
       "  TechSupport StreamingTV StreamingMovies        Contract PaperlessBilling  \\\n",
       "0          No          No              No  Month-to-month              Yes   \n",
       "1          No          No              No        One year               No   \n",
       "\n",
       "      PaymentMethod MonthlyCharges  TotalCharges Churn  \n",
       "0  Electronic check          29.85         29.85     0  \n",
       "1      Mailed check          56.95        1889.5     0  \n",
       "\n",
       "[2 rows x 21 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3e60bcbb-620b-4dca-8a39-533a5d8cf9d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline \n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, FunctionTransformer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cc936ba0-2aba-4bc1-9dad-a9e01d3d1a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns = []\n",
    "numerical_columns = []\n",
    "target = 'Churn'\n",
    "excluded_columns = ['customerID', 'TotalCharges', 'gender']\n",
    "\n",
    "for column in df.columns:\n",
    "    if column in excluded_columns + [target]:\n",
    "        continue\n",
    "    unique_values = df[column].nunique()\n",
    "    if unique_values <= 4:\n",
    "        categorical_columns.append(column)\n",
    "    else:\n",
    "        numerical_columns.append(column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5a74eaee-42c7-47eb-acb3-43c2c8d9198c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_columns(X):\n",
    "    return X.drop(columns=excluded_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7f52d651-9322-4d73-9e92-3d29c61471a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = ColumnTransformer([\n",
    "    ('Scaling', StandardScaler(), numerical_columns),\n",
    "    ('Ecoding', OneHotEncoder(), categorical_columns),\n",
    "])\n",
    "pipepline = Pipeline([\n",
    "    ('drop', FunctionTransformer(drop_columns)),\n",
    "    ('prepro', preprocessor)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "102ad087-c61a-484f-8ac6-754fb1b00982",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.drop(columns=target)\n",
    "y = df[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "02569240-7690-4f3c-ae00-d9ba356189d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_transformed = pipepline.fit_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "40727b7e-bd52-4a4b-98f8-8dd49ea3f88f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_transformed, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the neural network model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "771fa9c9-6be5-4d81-95e3-9e54219dc77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = X_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "29a4fdd8-5338-4204-a1d7-04e06631fa17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "63d886e0-c81b-4789-9a19-5191cbbfcc55",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/keras/src/layers/core/input_layer.py:26: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "  # Determine input shape dynamically\n",
    "model = tf.keras.Sequential([\n",
    "    InputLayer(input_shape=(input_shape,)),\n",
    "    Dense(128, activation=\"relu\"),\n",
    "    Dense(64, activation=\"relu\"),\n",
    "    Dense(32, activation=\"sigmoid\"),\n",
    "    Dense(2, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "5d74afa7-6226-4b26-8832-39eb751bb972",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "d3e0dd50-5348-48b1-9c15-62a8a8d1707c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 622us/step - accuracy: 0.7668 - loss: 0.4873 - val_accuracy: 0.8070 - val_loss: 0.4036\n",
      "Epoch 2/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 350us/step - accuracy: 0.8025 - loss: 0.4183 - val_accuracy: 0.8027 - val_loss: 0.4098\n",
      "Epoch 3/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 348us/step - accuracy: 0.7985 - loss: 0.4161 - val_accuracy: 0.8027 - val_loss: 0.4180\n",
      "Epoch 4/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 357us/step - accuracy: 0.8097 - loss: 0.4109 - val_accuracy: 0.8112 - val_loss: 0.4034\n",
      "Epoch 5/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 345us/step - accuracy: 0.7962 - loss: 0.4234 - val_accuracy: 0.8148 - val_loss: 0.4001\n",
      "Epoch 6/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 344us/step - accuracy: 0.8083 - loss: 0.3971 - val_accuracy: 0.8062 - val_loss: 0.4033\n",
      "Epoch 7/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 348us/step - accuracy: 0.8061 - loss: 0.4166 - val_accuracy: 0.8091 - val_loss: 0.4032\n",
      "Epoch 8/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 349us/step - accuracy: 0.7996 - loss: 0.4193 - val_accuracy: 0.8126 - val_loss: 0.4011\n",
      "Epoch 9/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 352us/step - accuracy: 0.8093 - loss: 0.4081 - val_accuracy: 0.8041 - val_loss: 0.4168\n",
      "Epoch 10/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 350us/step - accuracy: 0.8082 - loss: 0.4025 - val_accuracy: 0.8006 - val_loss: 0.4130\n",
      "Epoch 11/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 348us/step - accuracy: 0.8062 - loss: 0.4068 - val_accuracy: 0.7977 - val_loss: 0.4244\n",
      "Epoch 12/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 347us/step - accuracy: 0.8146 - loss: 0.4021 - val_accuracy: 0.8112 - val_loss: 0.4096\n",
      "Epoch 13/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 348us/step - accuracy: 0.8132 - loss: 0.3977 - val_accuracy: 0.8055 - val_loss: 0.4147\n",
      "Epoch 14/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 355us/step - accuracy: 0.8152 - loss: 0.3817 - val_accuracy: 0.7999 - val_loss: 0.4278\n",
      "Epoch 15/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 352us/step - accuracy: 0.8195 - loss: 0.3807 - val_accuracy: 0.7984 - val_loss: 0.4225\n",
      "Epoch 16/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 350us/step - accuracy: 0.8144 - loss: 0.3777 - val_accuracy: 0.7977 - val_loss: 0.4231\n",
      "Epoch 17/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 349us/step - accuracy: 0.8201 - loss: 0.3807 - val_accuracy: 0.7928 - val_loss: 0.4290\n",
      "Epoch 18/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 597us/step - accuracy: 0.8177 - loss: 0.3778 - val_accuracy: 0.7857 - val_loss: 0.4333\n",
      "Epoch 19/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 358us/step - accuracy: 0.8275 - loss: 0.3636 - val_accuracy: 0.7871 - val_loss: 0.4405\n",
      "Epoch 20/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 360us/step - accuracy: 0.8309 - loss: 0.3631 - val_accuracy: 0.7800 - val_loss: 0.4461\n",
      "Epoch 21/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 356us/step - accuracy: 0.8280 - loss: 0.3547 - val_accuracy: 0.7850 - val_loss: 0.4459\n",
      "Epoch 22/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 359us/step - accuracy: 0.8337 - loss: 0.3326 - val_accuracy: 0.7807 - val_loss: 0.4437\n",
      "Epoch 23/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 355us/step - accuracy: 0.8402 - loss: 0.3468 - val_accuracy: 0.7807 - val_loss: 0.4460\n",
      "Epoch 24/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 357us/step - accuracy: 0.8462 - loss: 0.3423 - val_accuracy: 0.7786 - val_loss: 0.4606\n",
      "Epoch 25/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 352us/step - accuracy: 0.8382 - loss: 0.3391 - val_accuracy: 0.7750 - val_loss: 0.4690\n",
      "Epoch 26/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 351us/step - accuracy: 0.8527 - loss: 0.3205 - val_accuracy: 0.7715 - val_loss: 0.4668\n",
      "Epoch 27/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 350us/step - accuracy: 0.8519 - loss: 0.3164 - val_accuracy: 0.7807 - val_loss: 0.4863\n",
      "Epoch 28/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 354us/step - accuracy: 0.8354 - loss: 0.3343 - val_accuracy: 0.7800 - val_loss: 0.4959\n",
      "Epoch 29/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 360us/step - accuracy: 0.8591 - loss: 0.3048 - val_accuracy: 0.7651 - val_loss: 0.4997\n",
      "Epoch 30/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 355us/step - accuracy: 0.8491 - loss: 0.3249 - val_accuracy: 0.7729 - val_loss: 0.5101\n",
      "Epoch 31/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 354us/step - accuracy: 0.8580 - loss: 0.3057 - val_accuracy: 0.7729 - val_loss: 0.4976\n",
      "Epoch 32/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 352us/step - accuracy: 0.8670 - loss: 0.2945 - val_accuracy: 0.7644 - val_loss: 0.5088\n",
      "Epoch 33/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 358us/step - accuracy: 0.8678 - loss: 0.2849 - val_accuracy: 0.7821 - val_loss: 0.5089\n",
      "Epoch 34/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 347us/step - accuracy: 0.8674 - loss: 0.2867 - val_accuracy: 0.7566 - val_loss: 0.5530\n",
      "Epoch 35/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 358us/step - accuracy: 0.8634 - loss: 0.3013 - val_accuracy: 0.7637 - val_loss: 0.5426\n",
      "Epoch 36/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 358us/step - accuracy: 0.8741 - loss: 0.2725 - val_accuracy: 0.7615 - val_loss: 0.5383\n",
      "Epoch 37/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 354us/step - accuracy: 0.8752 - loss: 0.2787 - val_accuracy: 0.7672 - val_loss: 0.5447\n",
      "Epoch 38/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 349us/step - accuracy: 0.8780 - loss: 0.2583 - val_accuracy: 0.7630 - val_loss: 0.5680\n",
      "Epoch 39/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 349us/step - accuracy: 0.8767 - loss: 0.2689 - val_accuracy: 0.7729 - val_loss: 0.5609\n",
      "Epoch 40/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 349us/step - accuracy: 0.8866 - loss: 0.2556 - val_accuracy: 0.7580 - val_loss: 0.5732\n",
      "Epoch 41/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 347us/step - accuracy: 0.8914 - loss: 0.2465 - val_accuracy: 0.7658 - val_loss: 0.5885\n",
      "Epoch 42/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 349us/step - accuracy: 0.8886 - loss: 0.2407 - val_accuracy: 0.7679 - val_loss: 0.6117\n",
      "Epoch 43/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 351us/step - accuracy: 0.8849 - loss: 0.2449 - val_accuracy: 0.7544 - val_loss: 0.6081\n",
      "Epoch 44/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 349us/step - accuracy: 0.8937 - loss: 0.2362 - val_accuracy: 0.7587 - val_loss: 0.6242\n",
      "Epoch 45/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 346us/step - accuracy: 0.8987 - loss: 0.2277 - val_accuracy: 0.7523 - val_loss: 0.6275\n",
      "Epoch 46/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 349us/step - accuracy: 0.8967 - loss: 0.2212 - val_accuracy: 0.7615 - val_loss: 0.6525\n",
      "Epoch 47/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 349us/step - accuracy: 0.9014 - loss: 0.2216 - val_accuracy: 0.7622 - val_loss: 0.6490\n",
      "Epoch 48/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 351us/step - accuracy: 0.8931 - loss: 0.2333 - val_accuracy: 0.7530 - val_loss: 0.6826\n",
      "Epoch 49/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 350us/step - accuracy: 0.8938 - loss: 0.2243 - val_accuracy: 0.7551 - val_loss: 0.6872\n",
      "Epoch 50/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 358us/step - accuracy: 0.8994 - loss: 0.2196 - val_accuracy: 0.7637 - val_loss: 0.7017\n",
      "Epoch 51/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 355us/step - accuracy: 0.9033 - loss: 0.2166 - val_accuracy: 0.7495 - val_loss: 0.6921\n",
      "Epoch 52/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 356us/step - accuracy: 0.9018 - loss: 0.2213 - val_accuracy: 0.7480 - val_loss: 0.7053\n",
      "Epoch 53/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 357us/step - accuracy: 0.9109 - loss: 0.1983 - val_accuracy: 0.7537 - val_loss: 0.7084\n",
      "Epoch 54/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 350us/step - accuracy: 0.9118 - loss: 0.1984 - val_accuracy: 0.7473 - val_loss: 0.7522\n",
      "Epoch 55/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 354us/step - accuracy: 0.9046 - loss: 0.2054 - val_accuracy: 0.7601 - val_loss: 0.7428\n",
      "Epoch 56/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 591us/step - accuracy: 0.9172 - loss: 0.1850 - val_accuracy: 0.7488 - val_loss: 0.7547\n",
      "Epoch 57/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 348us/step - accuracy: 0.9196 - loss: 0.1835 - val_accuracy: 0.7729 - val_loss: 0.7389\n",
      "Epoch 58/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 343us/step - accuracy: 0.9107 - loss: 0.2031 - val_accuracy: 0.7452 - val_loss: 0.7598\n",
      "Epoch 59/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 348us/step - accuracy: 0.9168 - loss: 0.1877 - val_accuracy: 0.7551 - val_loss: 0.7736\n",
      "Epoch 60/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 358us/step - accuracy: 0.9156 - loss: 0.1844 - val_accuracy: 0.7700 - val_loss: 0.7864\n",
      "Epoch 61/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 358us/step - accuracy: 0.9140 - loss: 0.1839 - val_accuracy: 0.7672 - val_loss: 0.7801\n",
      "Epoch 62/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 352us/step - accuracy: 0.9172 - loss: 0.1827 - val_accuracy: 0.7594 - val_loss: 0.8109\n",
      "Epoch 63/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 351us/step - accuracy: 0.9194 - loss: 0.1823 - val_accuracy: 0.7566 - val_loss: 0.8072\n",
      "Epoch 64/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 346us/step - accuracy: 0.9254 - loss: 0.1710 - val_accuracy: 0.7580 - val_loss: 0.8020\n",
      "Epoch 65/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 355us/step - accuracy: 0.9205 - loss: 0.1839 - val_accuracy: 0.7488 - val_loss: 0.8251\n",
      "Epoch 66/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 353us/step - accuracy: 0.9213 - loss: 0.1754 - val_accuracy: 0.7431 - val_loss: 0.8405\n",
      "Epoch 67/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 355us/step - accuracy: 0.9092 - loss: 0.2059 - val_accuracy: 0.7637 - val_loss: 0.8318\n",
      "Epoch 68/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 367us/step - accuracy: 0.9262 - loss: 0.1672 - val_accuracy: 0.7559 - val_loss: 0.8189\n",
      "Epoch 69/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 350us/step - accuracy: 0.9249 - loss: 0.1758 - val_accuracy: 0.7551 - val_loss: 0.8425\n",
      "Epoch 70/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 354us/step - accuracy: 0.9234 - loss: 0.1726 - val_accuracy: 0.7473 - val_loss: 0.8756\n",
      "Epoch 71/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 352us/step - accuracy: 0.9202 - loss: 0.1771 - val_accuracy: 0.7608 - val_loss: 0.8225\n",
      "Epoch 72/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 347us/step - accuracy: 0.9205 - loss: 0.1732 - val_accuracy: 0.7573 - val_loss: 0.8611\n",
      "Epoch 73/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 344us/step - accuracy: 0.9267 - loss: 0.1575 - val_accuracy: 0.7410 - val_loss: 0.9045\n",
      "Epoch 74/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 347us/step - accuracy: 0.9226 - loss: 0.1656 - val_accuracy: 0.7686 - val_loss: 0.8591\n",
      "Epoch 75/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 350us/step - accuracy: 0.9236 - loss: 0.1667 - val_accuracy: 0.7473 - val_loss: 0.8937\n",
      "Epoch 76/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 355us/step - accuracy: 0.9284 - loss: 0.1553 - val_accuracy: 0.7594 - val_loss: 0.8915\n",
      "Epoch 77/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 353us/step - accuracy: 0.9265 - loss: 0.1604 - val_accuracy: 0.7651 - val_loss: 0.9202\n",
      "Epoch 78/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 349us/step - accuracy: 0.9279 - loss: 0.1562 - val_accuracy: 0.7615 - val_loss: 0.9222\n",
      "Epoch 79/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 354us/step - accuracy: 0.9211 - loss: 0.1657 - val_accuracy: 0.7459 - val_loss: 0.9199\n",
      "Epoch 80/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 354us/step - accuracy: 0.9253 - loss: 0.1625 - val_accuracy: 0.7679 - val_loss: 0.8944\n",
      "Epoch 81/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 353us/step - accuracy: 0.9327 - loss: 0.1557 - val_accuracy: 0.7587 - val_loss: 0.9242\n",
      "Epoch 82/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 599us/step - accuracy: 0.9245 - loss: 0.1584 - val_accuracy: 0.7551 - val_loss: 0.9478\n",
      "Epoch 83/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 352us/step - accuracy: 0.9295 - loss: 0.1479 - val_accuracy: 0.7566 - val_loss: 0.9122\n",
      "Epoch 84/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 348us/step - accuracy: 0.9275 - loss: 0.1555 - val_accuracy: 0.7395 - val_loss: 0.9427\n",
      "Epoch 85/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 349us/step - accuracy: 0.9268 - loss: 0.1612 - val_accuracy: 0.7601 - val_loss: 0.9716\n",
      "Epoch 86/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 350us/step - accuracy: 0.9337 - loss: 0.1448 - val_accuracy: 0.7445 - val_loss: 0.9611\n",
      "Epoch 87/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 381us/step - accuracy: 0.9267 - loss: 0.1465 - val_accuracy: 0.7537 - val_loss: 0.9647\n",
      "Epoch 88/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 352us/step - accuracy: 0.9266 - loss: 0.1564 - val_accuracy: 0.7466 - val_loss: 1.0006\n",
      "Epoch 89/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 354us/step - accuracy: 0.9328 - loss: 0.1463 - val_accuracy: 0.7495 - val_loss: 0.9581\n",
      "Epoch 90/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 353us/step - accuracy: 0.9314 - loss: 0.1522 - val_accuracy: 0.7559 - val_loss: 0.9980\n",
      "Epoch 91/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 351us/step - accuracy: 0.9342 - loss: 0.1477 - val_accuracy: 0.7566 - val_loss: 0.9818\n",
      "Epoch 92/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 348us/step - accuracy: 0.9293 - loss: 0.1464 - val_accuracy: 0.7615 - val_loss: 0.9834\n",
      "Epoch 93/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 349us/step - accuracy: 0.9355 - loss: 0.1400 - val_accuracy: 0.7509 - val_loss: 1.0105\n",
      "Epoch 94/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 347us/step - accuracy: 0.9334 - loss: 0.1458 - val_accuracy: 0.7686 - val_loss: 1.0152\n",
      "Epoch 95/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 351us/step - accuracy: 0.9322 - loss: 0.1481 - val_accuracy: 0.7644 - val_loss: 1.0287\n",
      "Epoch 96/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 348us/step - accuracy: 0.9320 - loss: 0.1460 - val_accuracy: 0.7530 - val_loss: 1.0796\n",
      "Epoch 97/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 350us/step - accuracy: 0.9328 - loss: 0.1492 - val_accuracy: 0.7601 - val_loss: 1.0104\n",
      "Epoch 98/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 352us/step - accuracy: 0.9337 - loss: 0.1387 - val_accuracy: 0.7559 - val_loss: 1.0096\n",
      "Epoch 99/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 349us/step - accuracy: 0.9297 - loss: 0.1499 - val_accuracy: 0.7502 - val_loss: 1.0393\n",
      "Epoch 100/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 348us/step - accuracy: 0.9330 - loss: 0.1378 - val_accuracy: 0.7544 - val_loss: 1.0304\n",
      "Epoch 101/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 349us/step - accuracy: 0.9316 - loss: 0.1461 - val_accuracy: 0.7573 - val_loss: 1.0394\n",
      "Epoch 102/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 347us/step - accuracy: 0.9363 - loss: 0.1347 - val_accuracy: 0.7523 - val_loss: 1.0688\n",
      "Epoch 103/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 584us/step - accuracy: 0.9368 - loss: 0.1350 - val_accuracy: 0.7622 - val_loss: 1.0160\n",
      "Epoch 104/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 349us/step - accuracy: 0.9345 - loss: 0.1435 - val_accuracy: 0.7445 - val_loss: 1.1488\n",
      "Epoch 105/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 348us/step - accuracy: 0.9326 - loss: 0.1447 - val_accuracy: 0.7473 - val_loss: 1.0796\n",
      "Epoch 106/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 347us/step - accuracy: 0.9282 - loss: 0.1378 - val_accuracy: 0.7559 - val_loss: 1.1239\n",
      "Epoch 107/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 352us/step - accuracy: 0.9379 - loss: 0.1367 - val_accuracy: 0.7410 - val_loss: 1.1486\n",
      "Epoch 108/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 347us/step - accuracy: 0.9372 - loss: 0.1428 - val_accuracy: 0.7480 - val_loss: 1.0748\n",
      "Epoch 109/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 348us/step - accuracy: 0.9376 - loss: 0.1357 - val_accuracy: 0.7509 - val_loss: 1.0802\n",
      "Epoch 110/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 351us/step - accuracy: 0.9370 - loss: 0.1408 - val_accuracy: 0.7459 - val_loss: 1.1226\n",
      "Epoch 111/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 350us/step - accuracy: 0.9340 - loss: 0.1342 - val_accuracy: 0.7566 - val_loss: 1.1296\n",
      "Epoch 112/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 348us/step - accuracy: 0.9416 - loss: 0.1320 - val_accuracy: 0.7637 - val_loss: 1.1222\n",
      "Epoch 113/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 347us/step - accuracy: 0.9217 - loss: 0.1544 - val_accuracy: 0.7672 - val_loss: 1.1050\n",
      "Epoch 114/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 351us/step - accuracy: 0.9323 - loss: 0.1432 - val_accuracy: 0.7615 - val_loss: 1.0979\n",
      "Epoch 115/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 349us/step - accuracy: 0.9370 - loss: 0.1358 - val_accuracy: 0.7566 - val_loss: 1.1712\n",
      "Epoch 116/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 351us/step - accuracy: 0.9341 - loss: 0.1421 - val_accuracy: 0.7480 - val_loss: 1.1644\n",
      "Epoch 117/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 346us/step - accuracy: 0.9388 - loss: 0.1269 - val_accuracy: 0.7480 - val_loss: 1.1644\n",
      "Epoch 118/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 349us/step - accuracy: 0.9314 - loss: 0.1428 - val_accuracy: 0.7601 - val_loss: 1.1689\n",
      "Epoch 119/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 349us/step - accuracy: 0.9380 - loss: 0.1382 - val_accuracy: 0.7530 - val_loss: 1.1900\n",
      "Epoch 120/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 350us/step - accuracy: 0.9337 - loss: 0.1298 - val_accuracy: 0.7473 - val_loss: 1.1853\n",
      "Epoch 121/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 351us/step - accuracy: 0.9366 - loss: 0.1329 - val_accuracy: 0.7402 - val_loss: 1.2284\n",
      "Epoch 122/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 350us/step - accuracy: 0.9348 - loss: 0.1336 - val_accuracy: 0.7544 - val_loss: 1.1970\n",
      "Epoch 123/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 349us/step - accuracy: 0.9419 - loss: 0.1284 - val_accuracy: 0.7438 - val_loss: 1.2013\n",
      "Epoch 124/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 349us/step - accuracy: 0.9325 - loss: 0.1423 - val_accuracy: 0.7502 - val_loss: 1.2400\n",
      "Epoch 125/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 351us/step - accuracy: 0.9372 - loss: 0.1298 - val_accuracy: 0.7601 - val_loss: 1.1788\n",
      "Epoch 126/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 350us/step - accuracy: 0.9397 - loss: 0.1363 - val_accuracy: 0.7551 - val_loss: 1.2044\n",
      "Epoch 127/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 355us/step - accuracy: 0.9399 - loss: 0.1271 - val_accuracy: 0.7544 - val_loss: 1.2260\n",
      "Epoch 128/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 352us/step - accuracy: 0.9303 - loss: 0.1452 - val_accuracy: 0.7353 - val_loss: 1.3085\n",
      "Epoch 129/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 352us/step - accuracy: 0.9334 - loss: 0.1386 - val_accuracy: 0.7559 - val_loss: 1.2229\n",
      "Epoch 130/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 353us/step - accuracy: 0.9365 - loss: 0.1351 - val_accuracy: 0.7622 - val_loss: 1.2454\n",
      "Epoch 131/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 349us/step - accuracy: 0.9397 - loss: 0.1270 - val_accuracy: 0.7431 - val_loss: 1.2315\n",
      "Epoch 132/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 350us/step - accuracy: 0.9332 - loss: 0.1350 - val_accuracy: 0.7573 - val_loss: 1.3477\n",
      "Epoch 133/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 351us/step - accuracy: 0.9448 - loss: 0.1184 - val_accuracy: 0.7480 - val_loss: 1.2566\n",
      "Epoch 134/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 349us/step - accuracy: 0.9374 - loss: 0.1304 - val_accuracy: 0.7608 - val_loss: 1.2258\n",
      "Epoch 135/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 351us/step - accuracy: 0.9361 - loss: 0.1283 - val_accuracy: 0.7537 - val_loss: 1.2566\n",
      "Epoch 136/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 351us/step - accuracy: 0.9396 - loss: 0.1279 - val_accuracy: 0.7438 - val_loss: 1.2190\n",
      "Epoch 137/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 348us/step - accuracy: 0.9410 - loss: 0.1263 - val_accuracy: 0.7417 - val_loss: 1.2945\n",
      "Epoch 138/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 347us/step - accuracy: 0.9385 - loss: 0.1257 - val_accuracy: 0.7630 - val_loss: 1.3125\n",
      "Epoch 139/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 350us/step - accuracy: 0.9372 - loss: 0.1263 - val_accuracy: 0.7559 - val_loss: 1.2787\n",
      "Epoch 140/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 347us/step - accuracy: 0.9419 - loss: 0.1256 - val_accuracy: 0.7537 - val_loss: 1.3336\n",
      "Epoch 141/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 347us/step - accuracy: 0.9398 - loss: 0.1180 - val_accuracy: 0.7473 - val_loss: 1.3196\n",
      "Epoch 142/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 355us/step - accuracy: 0.9294 - loss: 0.1400 - val_accuracy: 0.7516 - val_loss: 1.3175\n",
      "Epoch 143/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 349us/step - accuracy: 0.9415 - loss: 0.1232 - val_accuracy: 0.7523 - val_loss: 1.2769\n",
      "Epoch 144/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 348us/step - accuracy: 0.9345 - loss: 0.1272 - val_accuracy: 0.7551 - val_loss: 1.3322\n",
      "Epoch 145/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 346us/step - accuracy: 0.9300 - loss: 0.1399 - val_accuracy: 0.7630 - val_loss: 1.2968\n",
      "Epoch 146/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 347us/step - accuracy: 0.9358 - loss: 0.1257 - val_accuracy: 0.7388 - val_loss: 1.3841\n",
      "Epoch 147/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 348us/step - accuracy: 0.9465 - loss: 0.1143 - val_accuracy: 0.7495 - val_loss: 1.2947\n",
      "Epoch 148/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 348us/step - accuracy: 0.9454 - loss: 0.1155 - val_accuracy: 0.7537 - val_loss: 1.3534\n",
      "Epoch 149/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 347us/step - accuracy: 0.9393 - loss: 0.1268 - val_accuracy: 0.7466 - val_loss: 1.3707\n",
      "Epoch 150/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 349us/step - accuracy: 0.9376 - loss: 0.1299 - val_accuracy: 0.7452 - val_loss: 1.3904\n",
      "Epoch 151/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 349us/step - accuracy: 0.9410 - loss: 0.1235 - val_accuracy: 0.7544 - val_loss: 1.3387\n",
      "Epoch 152/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 348us/step - accuracy: 0.9362 - loss: 0.1225 - val_accuracy: 0.7495 - val_loss: 1.4037\n",
      "Epoch 153/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 349us/step - accuracy: 0.9416 - loss: 0.1221 - val_accuracy: 0.7509 - val_loss: 1.4313\n",
      "Epoch 154/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 347us/step - accuracy: 0.9384 - loss: 0.1231 - val_accuracy: 0.7601 - val_loss: 1.3550\n",
      "Epoch 155/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 350us/step - accuracy: 0.9314 - loss: 0.1395 - val_accuracy: 0.7601 - val_loss: 1.4097\n",
      "Epoch 156/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 351us/step - accuracy: 0.9376 - loss: 0.1298 - val_accuracy: 0.7424 - val_loss: 1.4062\n",
      "Epoch 157/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 350us/step - accuracy: 0.9361 - loss: 0.1443 - val_accuracy: 0.7580 - val_loss: 1.3075\n",
      "Epoch 158/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 348us/step - accuracy: 0.9436 - loss: 0.1201 - val_accuracy: 0.7601 - val_loss: 1.3501\n",
      "Epoch 159/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 350us/step - accuracy: 0.9416 - loss: 0.1178 - val_accuracy: 0.7466 - val_loss: 1.4442\n",
      "Epoch 160/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 349us/step - accuracy: 0.9322 - loss: 0.1451 - val_accuracy: 0.7445 - val_loss: 1.3640\n",
      "Epoch 161/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 349us/step - accuracy: 0.9430 - loss: 0.1167 - val_accuracy: 0.7381 - val_loss: 1.4033\n",
      "Epoch 162/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 349us/step - accuracy: 0.9369 - loss: 0.1258 - val_accuracy: 0.7480 - val_loss: 1.4296\n",
      "Epoch 163/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 348us/step - accuracy: 0.9471 - loss: 0.1143 - val_accuracy: 0.7495 - val_loss: 1.3616\n",
      "Epoch 164/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 350us/step - accuracy: 0.9395 - loss: 0.1199 - val_accuracy: 0.7580 - val_loss: 1.3814\n",
      "Epoch 165/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 349us/step - accuracy: 0.9442 - loss: 0.1128 - val_accuracy: 0.7473 - val_loss: 1.3820\n",
      "Epoch 166/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 352us/step - accuracy: 0.9418 - loss: 0.1170 - val_accuracy: 0.7488 - val_loss: 1.4505\n",
      "Epoch 167/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 351us/step - accuracy: 0.9383 - loss: 0.1214 - val_accuracy: 0.7566 - val_loss: 1.4302\n",
      "Epoch 168/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 348us/step - accuracy: 0.9492 - loss: 0.1130 - val_accuracy: 0.7615 - val_loss: 1.4144\n",
      "Epoch 169/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 353us/step - accuracy: 0.9419 - loss: 0.1177 - val_accuracy: 0.7573 - val_loss: 1.3625\n",
      "Epoch 170/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 352us/step - accuracy: 0.9307 - loss: 0.1449 - val_accuracy: 0.7445 - val_loss: 1.4734\n",
      "Epoch 171/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 609us/step - accuracy: 0.9450 - loss: 0.1143 - val_accuracy: 0.7374 - val_loss: 1.4693\n",
      "Epoch 172/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 362us/step - accuracy: 0.9379 - loss: 0.1322 - val_accuracy: 0.7544 - val_loss: 1.4373\n",
      "Epoch 173/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 360us/step - accuracy: 0.9355 - loss: 0.1239 - val_accuracy: 0.7523 - val_loss: 1.4212\n",
      "Epoch 174/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 359us/step - accuracy: 0.9396 - loss: 0.1263 - val_accuracy: 0.7346 - val_loss: 1.4456\n",
      "Epoch 175/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 352us/step - accuracy: 0.9417 - loss: 0.1200 - val_accuracy: 0.7466 - val_loss: 1.4505\n",
      "Epoch 176/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 354us/step - accuracy: 0.9402 - loss: 0.1240 - val_accuracy: 0.7509 - val_loss: 1.3960\n",
      "Epoch 177/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 356us/step - accuracy: 0.9408 - loss: 0.1183 - val_accuracy: 0.7573 - val_loss: 1.4230\n",
      "Epoch 178/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 354us/step - accuracy: 0.9370 - loss: 0.1220 - val_accuracy: 0.7587 - val_loss: 1.4137\n",
      "Epoch 179/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 361us/step - accuracy: 0.9461 - loss: 0.1115 - val_accuracy: 0.7537 - val_loss: 1.4559\n",
      "Epoch 180/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 357us/step - accuracy: 0.9402 - loss: 0.1197 - val_accuracy: 0.7502 - val_loss: 1.4143\n",
      "Epoch 181/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 352us/step - accuracy: 0.9488 - loss: 0.1064 - val_accuracy: 0.7438 - val_loss: 1.5145\n",
      "Epoch 182/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 350us/step - accuracy: 0.9358 - loss: 0.1221 - val_accuracy: 0.7417 - val_loss: 1.5137\n",
      "Epoch 183/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 355us/step - accuracy: 0.9406 - loss: 0.1128 - val_accuracy: 0.7601 - val_loss: 1.4432\n",
      "Epoch 184/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 376us/step - accuracy: 0.9481 - loss: 0.1116 - val_accuracy: 0.7544 - val_loss: 1.4928\n",
      "Epoch 185/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 360us/step - accuracy: 0.9443 - loss: 0.1105 - val_accuracy: 0.7537 - val_loss: 1.4670\n",
      "Epoch 186/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 358us/step - accuracy: 0.9409 - loss: 0.1123 - val_accuracy: 0.7495 - val_loss: 1.4801\n",
      "Epoch 187/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 354us/step - accuracy: 0.9403 - loss: 0.1225 - val_accuracy: 0.7410 - val_loss: 1.5037\n",
      "Epoch 188/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 354us/step - accuracy: 0.9351 - loss: 0.1276 - val_accuracy: 0.7523 - val_loss: 1.5020\n",
      "Epoch 189/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 359us/step - accuracy: 0.9388 - loss: 0.1195 - val_accuracy: 0.7473 - val_loss: 1.4983\n",
      "Epoch 190/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 354us/step - accuracy: 0.9396 - loss: 0.1249 - val_accuracy: 0.7537 - val_loss: 1.5244\n",
      "Epoch 191/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 359us/step - accuracy: 0.9333 - loss: 0.1325 - val_accuracy: 0.7523 - val_loss: 1.4921\n",
      "Epoch 192/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 354us/step - accuracy: 0.9400 - loss: 0.1204 - val_accuracy: 0.7417 - val_loss: 1.5497\n",
      "Epoch 193/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 352us/step - accuracy: 0.9465 - loss: 0.1081 - val_accuracy: 0.7459 - val_loss: 1.5185\n",
      "Epoch 194/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 349us/step - accuracy: 0.9445 - loss: 0.1081 - val_accuracy: 0.7445 - val_loss: 1.4826\n",
      "Epoch 195/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 353us/step - accuracy: 0.9468 - loss: 0.1117 - val_accuracy: 0.7502 - val_loss: 1.5597\n",
      "Epoch 196/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 354us/step - accuracy: 0.9434 - loss: 0.1130 - val_accuracy: 0.7523 - val_loss: 1.5121\n",
      "Epoch 197/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 360us/step - accuracy: 0.9364 - loss: 0.1279 - val_accuracy: 0.7388 - val_loss: 1.4808\n",
      "Epoch 198/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 356us/step - accuracy: 0.9401 - loss: 0.1146 - val_accuracy: 0.7480 - val_loss: 1.5256\n",
      "Epoch 199/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 354us/step - accuracy: 0.9395 - loss: 0.1224 - val_accuracy: 0.7523 - val_loss: 1.5398\n",
      "Epoch 200/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 348us/step - accuracy: 0.9362 - loss: 0.1288 - val_accuracy: 0.7530 - val_loss: 1.4946\n",
      "Epoch 201/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 357us/step - accuracy: 0.9468 - loss: 0.1078 - val_accuracy: 0.7452 - val_loss: 1.5328\n",
      "Epoch 202/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 360us/step - accuracy: 0.9303 - loss: 0.1628 - val_accuracy: 0.7424 - val_loss: 1.4283\n",
      "Epoch 203/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 353us/step - accuracy: 0.9421 - loss: 0.1187 - val_accuracy: 0.7360 - val_loss: 1.4977\n",
      "Epoch 204/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 358us/step - accuracy: 0.9381 - loss: 0.1216 - val_accuracy: 0.7566 - val_loss: 1.5116\n",
      "Epoch 205/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 350us/step - accuracy: 0.9449 - loss: 0.1090 - val_accuracy: 0.7608 - val_loss: 1.4703\n",
      "Epoch 206/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 352us/step - accuracy: 0.9440 - loss: 0.1106 - val_accuracy: 0.7466 - val_loss: 1.5819\n",
      "Epoch 207/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 350us/step - accuracy: 0.9443 - loss: 0.1095 - val_accuracy: 0.7544 - val_loss: 1.6248\n",
      "Epoch 208/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 350us/step - accuracy: 0.9485 - loss: 0.1043 - val_accuracy: 0.7587 - val_loss: 1.4969\n",
      "Epoch 209/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 351us/step - accuracy: 0.9469 - loss: 0.1040 - val_accuracy: 0.7587 - val_loss: 1.5487\n",
      "Epoch 210/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 349us/step - accuracy: 0.9449 - loss: 0.1071 - val_accuracy: 0.7495 - val_loss: 1.5575\n",
      "Epoch 211/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 353us/step - accuracy: 0.9389 - loss: 0.1180 - val_accuracy: 0.7438 - val_loss: 1.6305\n",
      "Epoch 212/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 350us/step - accuracy: 0.9370 - loss: 0.1247 - val_accuracy: 0.7537 - val_loss: 1.5730\n",
      "Epoch 213/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 352us/step - accuracy: 0.9463 - loss: 0.1062 - val_accuracy: 0.7608 - val_loss: 1.6510\n",
      "Epoch 214/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 354us/step - accuracy: 0.9390 - loss: 0.1102 - val_accuracy: 0.7516 - val_loss: 1.5969\n",
      "Epoch 215/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 350us/step - accuracy: 0.9451 - loss: 0.1069 - val_accuracy: 0.7530 - val_loss: 1.6002\n",
      "Epoch 216/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 349us/step - accuracy: 0.9418 - loss: 0.1134 - val_accuracy: 0.7509 - val_loss: 1.6812\n",
      "Epoch 217/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 353us/step - accuracy: 0.9353 - loss: 0.1325 - val_accuracy: 0.7509 - val_loss: 1.6279\n",
      "Epoch 218/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 350us/step - accuracy: 0.9455 - loss: 0.1149 - val_accuracy: 0.7601 - val_loss: 1.6401\n",
      "Epoch 219/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 360us/step - accuracy: 0.9428 - loss: 0.1192 - val_accuracy: 0.7537 - val_loss: 1.5916\n",
      "Epoch 220/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 351us/step - accuracy: 0.9485 - loss: 0.1043 - val_accuracy: 0.7438 - val_loss: 1.6240\n",
      "Epoch 221/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 352us/step - accuracy: 0.9419 - loss: 0.1204 - val_accuracy: 0.7473 - val_loss: 1.6116\n",
      "Epoch 222/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 351us/step - accuracy: 0.9452 - loss: 0.1104 - val_accuracy: 0.7559 - val_loss: 1.5962\n",
      "Epoch 223/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 349us/step - accuracy: 0.9438 - loss: 0.1147 - val_accuracy: 0.7559 - val_loss: 1.6842\n",
      "Epoch 224/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 601us/step - accuracy: 0.9467 - loss: 0.1039 - val_accuracy: 0.7601 - val_loss: 1.6421\n",
      "Epoch 225/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 365us/step - accuracy: 0.9380 - loss: 0.1235 - val_accuracy: 0.7551 - val_loss: 1.7075\n",
      "Epoch 226/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 357us/step - accuracy: 0.9433 - loss: 0.1116 - val_accuracy: 0.7473 - val_loss: 1.7498\n",
      "Epoch 227/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 358us/step - accuracy: 0.9434 - loss: 0.1079 - val_accuracy: 0.7523 - val_loss: 1.7302\n",
      "Epoch 228/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 359us/step - accuracy: 0.9353 - loss: 0.1203 - val_accuracy: 0.7473 - val_loss: 1.7075\n",
      "Epoch 229/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 358us/step - accuracy: 0.9508 - loss: 0.1022 - val_accuracy: 0.7594 - val_loss: 1.6753\n",
      "Epoch 230/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 384us/step - accuracy: 0.9456 - loss: 0.1184 - val_accuracy: 0.7601 - val_loss: 1.6524\n",
      "Epoch 231/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 360us/step - accuracy: 0.9418 - loss: 0.1320 - val_accuracy: 0.7473 - val_loss: 1.6718\n",
      "Epoch 232/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 356us/step - accuracy: 0.9452 - loss: 0.1039 - val_accuracy: 0.7445 - val_loss: 1.6847\n",
      "Epoch 233/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 358us/step - accuracy: 0.9486 - loss: 0.1055 - val_accuracy: 0.7395 - val_loss: 1.6379\n",
      "Epoch 234/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 374us/step - accuracy: 0.9436 - loss: 0.1102 - val_accuracy: 0.7480 - val_loss: 1.6778\n",
      "Epoch 235/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 367us/step - accuracy: 0.9457 - loss: 0.1084 - val_accuracy: 0.7438 - val_loss: 1.7008\n",
      "Epoch 236/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 355us/step - accuracy: 0.9456 - loss: 0.1062 - val_accuracy: 0.7495 - val_loss: 1.7499\n",
      "Epoch 237/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 358us/step - accuracy: 0.9443 - loss: 0.1053 - val_accuracy: 0.7452 - val_loss: 1.7913\n",
      "Epoch 238/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 356us/step - accuracy: 0.9447 - loss: 0.1134 - val_accuracy: 0.7544 - val_loss: 1.7717\n",
      "Epoch 239/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 356us/step - accuracy: 0.9475 - loss: 0.1093 - val_accuracy: 0.7495 - val_loss: 1.7247\n",
      "Epoch 240/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 361us/step - accuracy: 0.9459 - loss: 0.1064 - val_accuracy: 0.7544 - val_loss: 1.6877\n",
      "Epoch 241/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 359us/step - accuracy: 0.9523 - loss: 0.0997 - val_accuracy: 0.7424 - val_loss: 1.7860\n",
      "Epoch 242/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 356us/step - accuracy: 0.9417 - loss: 0.1148 - val_accuracy: 0.7509 - val_loss: 1.7484\n",
      "Epoch 243/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 353us/step - accuracy: 0.9458 - loss: 0.1122 - val_accuracy: 0.7509 - val_loss: 1.7284\n",
      "Epoch 244/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 355us/step - accuracy: 0.9464 - loss: 0.1049 - val_accuracy: 0.7516 - val_loss: 1.7434\n",
      "Epoch 245/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 357us/step - accuracy: 0.9425 - loss: 0.1123 - val_accuracy: 0.7452 - val_loss: 1.7582\n",
      "Epoch 246/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 359us/step - accuracy: 0.9489 - loss: 0.1031 - val_accuracy: 0.7381 - val_loss: 1.7792\n",
      "Epoch 247/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 356us/step - accuracy: 0.9452 - loss: 0.1111 - val_accuracy: 0.7473 - val_loss: 1.6806\n",
      "Epoch 248/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 357us/step - accuracy: 0.9446 - loss: 0.1091 - val_accuracy: 0.7480 - val_loss: 1.7244\n",
      "Epoch 249/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 359us/step - accuracy: 0.9421 - loss: 0.1060 - val_accuracy: 0.7410 - val_loss: 1.7856\n",
      "Epoch 250/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 357us/step - accuracy: 0.9328 - loss: 0.1319 - val_accuracy: 0.7502 - val_loss: 1.7915\n",
      "Epoch 251/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 362us/step - accuracy: 0.9472 - loss: 0.1064 - val_accuracy: 0.7339 - val_loss: 1.8631\n",
      "Epoch 252/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 379us/step - accuracy: 0.9420 - loss: 0.1143 - val_accuracy: 0.7417 - val_loss: 1.7839\n",
      "Epoch 253/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 373us/step - accuracy: 0.9494 - loss: 0.0983 - val_accuracy: 0.7353 - val_loss: 1.7518\n",
      "Epoch 254/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 373us/step - accuracy: 0.9471 - loss: 0.1089 - val_accuracy: 0.7424 - val_loss: 1.7892\n",
      "Epoch 255/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 374us/step - accuracy: 0.9523 - loss: 0.1009 - val_accuracy: 0.7502 - val_loss: 1.8239\n",
      "Epoch 256/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 367us/step - accuracy: 0.9476 - loss: 0.1050 - val_accuracy: 0.7480 - val_loss: 1.8149\n",
      "Epoch 257/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 358us/step - accuracy: 0.9494 - loss: 0.1014 - val_accuracy: 0.7459 - val_loss: 1.8400\n",
      "Epoch 258/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 352us/step - accuracy: 0.9459 - loss: 0.1082 - val_accuracy: 0.7424 - val_loss: 1.7844\n",
      "Epoch 259/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 354us/step - accuracy: 0.9415 - loss: 0.1155 - val_accuracy: 0.7445 - val_loss: 1.8785\n",
      "Epoch 260/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 357us/step - accuracy: 0.9404 - loss: 0.1120 - val_accuracy: 0.7488 - val_loss: 1.7700\n",
      "Epoch 261/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 360us/step - accuracy: 0.9418 - loss: 0.1149 - val_accuracy: 0.7530 - val_loss: 1.8333\n",
      "Epoch 262/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 361us/step - accuracy: 0.9448 - loss: 0.1120 - val_accuracy: 0.7431 - val_loss: 1.7545\n",
      "Epoch 263/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 358us/step - accuracy: 0.9520 - loss: 0.1017 - val_accuracy: 0.7395 - val_loss: 1.7906\n",
      "Epoch 264/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 351us/step - accuracy: 0.9408 - loss: 0.1072 - val_accuracy: 0.7438 - val_loss: 1.8175\n",
      "Epoch 265/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 355us/step - accuracy: 0.9472 - loss: 0.1028 - val_accuracy: 0.7395 - val_loss: 1.8242\n",
      "Epoch 266/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 355us/step - accuracy: 0.9419 - loss: 0.1125 - val_accuracy: 0.7530 - val_loss: 1.8063\n",
      "Epoch 267/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 357us/step - accuracy: 0.9468 - loss: 0.1042 - val_accuracy: 0.7495 - val_loss: 1.8257\n",
      "Epoch 268/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 360us/step - accuracy: 0.9421 - loss: 0.1113 - val_accuracy: 0.7488 - val_loss: 1.8495\n",
      "Epoch 269/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 358us/step - accuracy: 0.9418 - loss: 0.1100 - val_accuracy: 0.7424 - val_loss: 1.8012\n",
      "Epoch 270/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 364us/step - accuracy: 0.9427 - loss: 0.1143 - val_accuracy: 0.7473 - val_loss: 1.7904\n",
      "Epoch 271/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 357us/step - accuracy: 0.9500 - loss: 0.1010 - val_accuracy: 0.7530 - val_loss: 1.9206\n",
      "Epoch 272/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 358us/step - accuracy: 0.9435 - loss: 0.1051 - val_accuracy: 0.7573 - val_loss: 1.8245\n",
      "Epoch 273/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 359us/step - accuracy: 0.9478 - loss: 0.1030 - val_accuracy: 0.7402 - val_loss: 1.9250\n",
      "Epoch 274/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 381us/step - accuracy: 0.9483 - loss: 0.1021 - val_accuracy: 0.7509 - val_loss: 1.7608\n",
      "Epoch 275/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 381us/step - accuracy: 0.9492 - loss: 0.1046 - val_accuracy: 0.7502 - val_loss: 1.7350\n",
      "Epoch 276/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 376us/step - accuracy: 0.9450 - loss: 0.1022 - val_accuracy: 0.7480 - val_loss: 1.8588\n",
      "Epoch 277/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 366us/step - accuracy: 0.9484 - loss: 0.1062 - val_accuracy: 0.7544 - val_loss: 1.7334\n",
      "Epoch 278/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 379us/step - accuracy: 0.9476 - loss: 0.1050 - val_accuracy: 0.7502 - val_loss: 1.8259\n",
      "Epoch 279/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 379us/step - accuracy: 0.9467 - loss: 0.1041 - val_accuracy: 0.7431 - val_loss: 1.8903\n",
      "Epoch 280/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 412us/step - accuracy: 0.9461 - loss: 0.1015 - val_accuracy: 0.7573 - val_loss: 1.8300\n",
      "Epoch 281/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 387us/step - accuracy: 0.9447 - loss: 0.1011 - val_accuracy: 0.7466 - val_loss: 1.8707\n",
      "Epoch 282/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 656us/step - accuracy: 0.9414 - loss: 0.1121 - val_accuracy: 0.7438 - val_loss: 1.8838\n",
      "Epoch 283/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 416us/step - accuracy: 0.9432 - loss: 0.1153 - val_accuracy: 0.7480 - val_loss: 1.8476\n",
      "Epoch 284/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 424us/step - accuracy: 0.9424 - loss: 0.1139 - val_accuracy: 0.7417 - val_loss: 1.9981\n",
      "Epoch 285/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 374us/step - accuracy: 0.9418 - loss: 0.1090 - val_accuracy: 0.7573 - val_loss: 1.8926\n",
      "Epoch 286/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 670us/step - accuracy: 0.9457 - loss: 0.1049 - val_accuracy: 0.7530 - val_loss: 1.8729\n",
      "Epoch 287/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 378us/step - accuracy: 0.9501 - loss: 0.0997 - val_accuracy: 0.7516 - val_loss: 1.9368\n",
      "Epoch 288/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 385us/step - accuracy: 0.9477 - loss: 0.1035 - val_accuracy: 0.7488 - val_loss: 1.8560\n",
      "Epoch 289/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 378us/step - accuracy: 0.9466 - loss: 0.1021 - val_accuracy: 0.7388 - val_loss: 1.8602\n",
      "Epoch 290/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 569us/step - accuracy: 0.9494 - loss: 0.1049 - val_accuracy: 0.7495 - val_loss: 1.8872\n",
      "Epoch 291/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 647us/step - accuracy: 0.9434 - loss: 0.1186 - val_accuracy: 0.7445 - val_loss: 1.8253\n",
      "Epoch 292/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 378us/step - accuracy: 0.9424 - loss: 0.1106 - val_accuracy: 0.7516 - val_loss: 1.8562\n",
      "Epoch 293/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 683us/step - accuracy: 0.9463 - loss: 0.1042 - val_accuracy: 0.7480 - val_loss: 1.8932\n",
      "Epoch 294/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 358us/step - accuracy: 0.9495 - loss: 0.0974 - val_accuracy: 0.7544 - val_loss: 1.8736\n",
      "Epoch 295/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 639us/step - accuracy: 0.9499 - loss: 0.0991 - val_accuracy: 0.7488 - val_loss: 1.8628\n",
      "Epoch 296/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 355us/step - accuracy: 0.9469 - loss: 0.0996 - val_accuracy: 0.7473 - val_loss: 1.8957\n",
      "Epoch 297/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 634us/step - accuracy: 0.9485 - loss: 0.0996 - val_accuracy: 0.7530 - val_loss: 1.9548\n",
      "Epoch 298/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 374us/step - accuracy: 0.9465 - loss: 0.1015 - val_accuracy: 0.7587 - val_loss: 1.8684\n",
      "Epoch 299/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 636us/step - accuracy: 0.9502 - loss: 0.0988 - val_accuracy: 0.7502 - val_loss: 1.9238\n",
      "Epoch 300/300\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 360us/step - accuracy: 0.9503 - loss: 0.0959 - val_accuracy: 0.7580 - val_loss: 1.8617\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x312fedc50>"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=300, validation_data=(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "80477b49-0341-4e58-89fc-944a9b7700bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 532us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.4799344 , 0.6762104 ],\n",
       "       [0.47484723, 0.64561516],\n",
       "       [0.48325592, 0.67417765],\n",
       "       ...,\n",
       "       [0.48351115, 0.6634803 ],\n",
       "       [0.45274124, 0.65285677],\n",
       "       [0.47008267, 0.6781703 ]], dtype=float32)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "32769990-4a9c-4978-affb-e4d0a30c2f06",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 256us/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "b3730480-7c62-43a7-8205-33c92c85f030",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True, ...,  True,  True,  True])"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[0:, 0]>0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "25663e73-6ae5-4a8a-9e0c-b24e36f4c449",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "685ceb1d-5da9-4d5a-8fcd-df42044ba81a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 324us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[879, 157],\n",
       "       [184, 189]])"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions on the test data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Convert the probabilities to binary class predictions (0 or 1)\n",
    "y_pred_class = y_pred.argmax(axis=1)  # Takes the class with the highest probability (0 or 1)\n",
    "\n",
    "# Now you can generate and display the confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred_class)\n",
    "\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "d14bcd93-7097-4f87-a9e9-9e58e8e82a37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "08286484-5f13-469b-b265-6a8468fb581a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "185     1\n",
       "2715    0\n",
       "3825    0\n",
       "1807    1\n",
       "132     0\n",
       "       ..\n",
       "6366    0\n",
       "315     0\n",
       "2439    0\n",
       "5002    0\n",
       "1161    1\n",
       "Name: Churn, Length: 1409, dtype: int64"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad219cd-8114-4ce8-8df8-d18abe7e0d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f940af33-427e-401a-9318-4177ddb6b12d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 312us/step - accuracy: 0.7636 - loss: 0.5239\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a9f7da8d-b54c-49e8-9cdd-a56cbce77b4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7693399786949158"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d1398587-cee5-4e68-8b6c-56168cc724d8",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (4173444228.py, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[18], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    ,\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "                             InputLayer(input_shape = (8,)),\n",
    "                             ,\n",
    "                             Dense(128, activation = \"relu\"),\n",
    "                             Dense(128, activation = \"relu\"),\n",
    "                             Dense(128, activation = \"relu\"),\n",
    "                             Dense(2,activation = 'sigmoid')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a777f7de-82c0-4dab-8953-646896b03a92",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
